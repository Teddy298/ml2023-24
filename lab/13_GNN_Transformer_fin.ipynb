{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5348b57746426752"
      },
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "## Part II: Transformer\n",
        "We are going to play with attention in the context for molecular property prediciton. It's recommended that you're familiar with the recent lectures on GNNs and with the previous lab on MPNN in molecular property prediction."
      ],
      "id": "5348b57746426752"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2ddf75df96204316"
      },
      "source": [
        "# Setup\n",
        "We are going to use the same dataset and most of the codebase as in the previous lab."
      ],
      "id": "2ddf75df96204316"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OyxgJ3N-tao",
        "outputId": "296e817d-7cd0-4c18-8362-d3cc21de9c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgllife in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.2.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2023.3.post1)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dgllife\n",
        "!pip install dgl\n",
        "!pip install rdkit"
      ],
      "id": "-OyxgJ3N-tao"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cxNzZHD-vXF",
        "outputId": "e806dc21-4974-4119-d9f2-b4f2b813a455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.0.post0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install torch_geometric"
      ],
      "id": "2cxNzZHD-vXF"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f135qXZ-x1K",
        "outputId": "add2dddc-c7f6-45f2-94a1-63eddf23f878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.39.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ],
      "id": "5f135qXZ-x1K"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "hr7Vlnym-0QA",
        "outputId": "4417e408-0d66-4e40-c447-2f43c89b9e96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-484c388f-9e07-4772-bf0b-e152634511df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-484c388f-9e07-4772-bf0b-e152634511df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checker.py to checker.py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "id": "hr7Vlnym-0QA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "79e432bdca0c548d"
      },
      "source": [
        "## Copied code\n",
        "I'm going to copy most of the code for convenience."
      ],
      "id": "79e432bdca0c548d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5c423333bf850de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720e9828-3404-463f-f485-447f9d70dcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "from abc import ABC, abstractmethod\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple\n",
        "from typing import Type\n",
        "\n",
        "import dgl\n",
        "import numpy as np\n",
        "import torch\n",
        "from dgl.data import Subset\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from dgllife.data import FreeSolv\n",
        "from dgllife.utils import CanonicalAtomFeaturizer, SMILESToBigraph\n",
        "from dgllife.utils import ScaffoldSplitter\n",
        "from torch import nn\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torchmetrics import Metric\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "from checker import expected_gat_output, expected_dot_attention_output, sub_optimal_multihead_attention_output, \\\n",
        "    expected_multihead_attention_output"
      ],
      "id": "5c423333bf850de1"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "d1609cbd2996b027"
      },
      "outputs": [],
      "source": [
        "class LoggerBase(ABC):\n",
        "    def __init__(self, logdir: str | Path):\n",
        "        self.logdir = Path(logdir)\n",
        "        self.logdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    @abstractmethod\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def close(self):\n",
        "        ...\n",
        "\n",
        "\n",
        "class WandbLogger(LoggerBase):\n",
        "    def __init__(\n",
        "            self, logdir: str | Path, project_name: str, experiment_name: str, **kwargs: Dict[str, Any]\n",
        "    ):\n",
        "        super().__init__(logdir)\n",
        "        import wandb\n",
        "        self.project_name = project_name\n",
        "        self.experiment_name = experiment_name\n",
        "        self.kwargs = kwargs\n",
        "        self.run = wandb.init(\n",
        "            dir=self.logdir,\n",
        "            project=self.project_name,\n",
        "            name=self.experiment_name,\n",
        "            **self.kwargs,\n",
        "        )\n",
        "\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        metrics = {f\"{prefix}/{k}\": v for k, v in metrics.items()}\n",
        "        self.run.log(metrics)\n",
        "\n",
        "    def close(self):\n",
        "        self.run.finish()\n",
        "\n",
        "\n",
        "class DummyLogger(LoggerBase):  # If you don't want to use any logger, you can use this one\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    def restart(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class MetricList:\n",
        "    def __init__(self, metrics: Dict[str, Metric]):\n",
        "        self.metrics = copy.deepcopy(metrics)\n",
        "\n",
        "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
        "        for name, metric in self.metrics.items():\n",
        "            metric.update(preds.detach().cpu(), targets.cpu())\n",
        "\n",
        "    def compute(self) -> Dict[str, float]:\n",
        "        metrics = {}\n",
        "        for name, metric_fn in self.metrics.items():\n",
        "            metrics[name] = metric_fn.compute().item()\n",
        "            metric_fn.reset()\n",
        "        return metrics\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            *,\n",
        "            run_dir: str | Path,\n",
        "            train_dataset: Subset,\n",
        "            valid_dataset: Subset,\n",
        "            train_metrics: Dict[str, Metric],\n",
        "            valid_metrics: Dict[str, Metric],\n",
        "            model: nn.Module,\n",
        "            logger: LoggerBase,\n",
        "            optimizer_kwargs: Dict[str, Any],\n",
        "            optimizer_cls: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
        "            n_epochs: int,\n",
        "            train_batch_size: int = 32,\n",
        "            valid_batch_size: int = 16,\n",
        "            device: str = \"cuda\",\n",
        "            valid_every_n_epochs: int = 1,\n",
        "            loss_fn=nn.MSELoss()\n",
        "    ):\n",
        "        self.run_dir = Path(run_dir)\n",
        "        self.train_loader = GraphDataLoader(\n",
        "            dataset=train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.valid_loader = GraphDataLoader(\n",
        "            dataset=valid_dataset,\n",
        "            batch_size=valid_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.train_metrics = MetricList(train_metrics)\n",
        "        self.valid_metrics = MetricList(valid_metrics)\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer_cls(model.parameters(), **optimizer_kwargs)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "        self.valid_every_n_epochs = valid_every_n_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model.to(device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, dataloader: GraphDataLoader, prefix: str) -> Dict[str, float]:\n",
        "        previous_mode = self.model.training\n",
        "        self.model.eval()\n",
        "        losses = []\n",
        "        for _, graphs, labels in dataloader:\n",
        "            graphs = graphs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self.model(graphs)\n",
        "            loss = self.loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "            self.valid_metrics.update(preds, labels)\n",
        "        self.model.train(mode=previous_mode)\n",
        "        metrics = {\"loss\": np.mean(losses)} | self.valid_metrics.compute()\n",
        "        self.logger.log_metrics(metrics=metrics, prefix=prefix)\n",
        "        return metrics\n",
        "\n",
        "    def train(self) -> Dict[str, float]:\n",
        "        self.model.train()\n",
        "        valid_metrics = {}\n",
        "        for epoch in tqdm(range(self.n_epochs), total=self.n_epochs):\n",
        "            for _, graphs, labels in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                graphs = graphs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                preds = self.model(graphs)\n",
        "                loss = self.loss_fn(preds, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                self.train_metrics.update(preds, labels)\n",
        "                train_metrics = {\"loss\": loss.item()} | self.train_metrics.compute()\n",
        "                self.logger.log_metrics(metrics=train_metrics, prefix=\"train\")\n",
        "\n",
        "                if epoch % self.valid_every_n_epochs == 0 or epoch == self.n_epochs - 1:\n",
        "                    valid_metrics = self.validate(self.valid_loader, prefix=\"valid\")\n",
        "\n",
        "        return valid_metrics\n",
        "\n",
        "    def test(self, dataset: Subset) -> Dict[str, float]:\n",
        "        dataloader = GraphDataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=16,\n",
        "            shuffle=False,\n",
        "        )\n",
        "        return self.validate(dataloader, prefix=\"test\")\n",
        "\n",
        "    def close(self):  # close the logger, not really required for wandb\n",
        "        self.logger.close()"
      ],
      "id": "d1609cbd2996b027"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8808a77d7c57aed1"
      },
      "outputs": [],
      "source": [
        "def to_dense_embeddings(node_embeddings: torch.Tensor, graph: dgl.DGLGraph, fill_value: float = 0.0) -> Tuple[\n",
        "    torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts sparse node embeddings to dense node embeddings with padding.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        graph: a batch of graphs\n",
        "        fill_value: a value to fill the padding with\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    \"\"\"\n",
        "    num_nodes = graph.batch_num_nodes()  # e.g. [2, 3, 3]\n",
        "    indices = torch.arange(len(num_nodes), device=num_nodes.device)\n",
        "    batch = torch.repeat_interleave(indices, num_nodes).long()  # e.g. [0, 0, 1, 1, 1, 2, 2, 2]\n",
        "    return to_dense_batch(node_embeddings, batch,\n",
        "                          fill_value=fill_value)  # that's the only reason we have torch_geometric in the requirements\n",
        "\n",
        "\n",
        "def to_sparse_embeddings(node_embeddings: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Converts dense node embeddings to sparse node embeddings.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "    \"\"\"\n",
        "    return node_embeddings[mask]"
      ],
      "id": "8808a77d7c57aed1"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6071a391cab1d058"
      },
      "outputs": [],
      "source": [
        "class ReadoutBase(nn.Module, ABC):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, node_embeddings: torch.Tensor, graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        ...\n",
        "\n",
        "\n",
        "class SumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # We can also use dgl.sum_nodes function, but let assume it's forbidden in that notebook ;)\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        return node_embeddings.sum(dim=1)"
      ],
      "id": "6071a391cab1d058"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5fc0e088c6c18d87"
      },
      "source": [
        "## Updated code\n",
        "Some of the previous code is slightly updated."
      ],
      "id": "5fc0e088c6c18d87"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "482754c146bd3073"
      },
      "outputs": [],
      "source": [
        "class GNNLayerBase(ABC, nn.Module):\n",
        "    def _init(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor | None,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        ...\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 node_features_size: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size: int,\n",
        "                 gnn_layer_cls: Type[GNNLayerBase],\n",
        "                 gnn_layer_kwargs: Dict[str, Any],\n",
        "                 gnn_n_layers: int,\n",
        "                 gnn_layer_requires_dense: bool,\n",
        "                 readout_cls: Type[ReadoutBase]):\n",
        "        super().__init__()\n",
        "        self.linear_node = nn.Linear(node_features_size, hidden_size)\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            gnn_layer_cls(hidden_size=hidden_size, **gnn_layer_kwargs)\n",
        "            for _ in range(gnn_n_layers)\n",
        "        ])\n",
        "        self.readout = readout_cls(hidden_size=hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "        self.gnn_layer_requires_dense = gnn_layer_requires_dense\n",
        "\n",
        "    def forward(self, graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        node_embeddings = graph.ndata['h']\n",
        "        node_embeddings = self.linear_node(node_embeddings)\n",
        "        if self.gnn_layer_requires_dense:\n",
        "            node_embeddings, mask = to_dense_embeddings(node_embeddings, graph)\n",
        "        else:\n",
        "            mask = None\n",
        "        for layer in self.gnn_layers:\n",
        "            node_embeddings = layer(node_embeddings=node_embeddings, mask=mask, graph=graph)\n",
        "        if self.gnn_layer_requires_dense:\n",
        "            node_embeddings = to_sparse_embeddings(node_embeddings, mask)\n",
        "        graph_embedding = self.readout(node_embeddings, graph)\n",
        "        predictions = self.mlp(graph_embedding)\n",
        "        return predictions"
      ],
      "id": "482754c146bd3073"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2d82b677d7d9db4c"
      },
      "outputs": [],
      "source": [
        "def test_gnn_layer(mpnn_layer_cls: Type[GNNLayerBase], expected_output: torch.Tensor, requires_dense: bool = False):\n",
        "    node_featurizer = CanonicalAtomFeaturizer()\n",
        "    graph_a = SMILESToBigraph(node_featurizer=node_featurizer, add_self_loop=True)(\"CN(C)C(=O)c1ccc(cc1)OC\")\n",
        "    graph_b = SMILESToBigraph(node_featurizer=node_featurizer, add_self_loop=True)(\"CS(=O)(=O)Cl\")\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([graph_a, graph_b])\n",
        "    linear_nodes = nn.Linear(node_featurizer.feat_size(), 12)\n",
        "    node_embeddings = linear_nodes(graph.ndata['h'])\n",
        "    layer = mpnn_layer_cls(hidden_size=12)\n",
        "    if requires_dense:\n",
        "        node_embeddings, mask = to_dense_embeddings(node_embeddings, graph)\n",
        "    else:\n",
        "        mask = None\n",
        "    result = layer(node_embeddings=node_embeddings, mask=mask, graph=graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-4)"
      ],
      "id": "2d82b677d7d9db4c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "f029737734a971b4"
      },
      "source": [
        "# Attention\n",
        "As you know from the lectures, the Transformer architecture is based on the attention mechanism. However, it's worth noting that attention is not a mechanism from the Transformer architecture, but rather a general concept used many times before. We've actually used some form of attention in the previous lab in `AttentionReadout` class. It was aggregating the information from graph nodes by computing a weighted average of the nodes embeddings using dynamically computed weights. The attention in the Transformer architecture is very similar - the main difference is that attention in Transformer is computed for every token (node) and is used to update the token/node embedding. In the context of graphs, we have a second well-known attention-based architecture called [Graph Attention Network (GAT)](https://arxiv.org/abs/1710.10903). The attention in GAT differs from attention in Transformer in two ways:\n",
        "1. In GAT, the attention for a given node is computed using the node's neighbors while in Transformer it's computed using all other nodes.\n",
        "2. GAT uses additive attention, while Transformer uses (multiheaded) dot-product one.\n",
        "\n",
        "Let's start with implementation of GAT layer."
      ],
      "id": "f029737734a971b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "d0a9a8af402d16ee"
      },
      "source": [
        "## Additive attention (GAT)\n",
        "### Task 1. GATLayer (2 points).\n",
        "Your task is to:\n",
        "1\\) implement a GAT layer which is MPNN that uses attention mechanism for neighbor aggregation. The formula for the update is the following:\n",
        "$$\n",
        "m_i = W_1 x_i\n",
        "$$\n",
        "$$\n",
        "score_{ij} = LeakyReLU(W_2(m_i | m_j)),\n",
        "$$\n",
        "$$\n",
        "\\alpha_{ij} = \\frac{exp(score_{ij})}{\\sum_{k \\in \\mathcal{N}(i) \\cup \\{i\\}} exp(score_{ik})}\n",
        "$$\n",
        "$$\n",
        "x'_i = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\alpha_{ij} m_j\n",
        "$$\n",
        "where | stands for concatenation. Note that in our code, we added self-loops to the graph, so $\\mathcal{N}(i) \\cup \\{i\\} = \\mathcal{N}(i)$.\n",
        "\n",
        "2\\) Briefly explain why the attention in GAT is called additive:\n",
        "\n",
        "Your explanation: The attention mechanism in Graph Attention Networks (GAT) is called \"additive\" because it utilizes a weighted sum of neighbour node features multiplied by learned attention coefficients."
      ],
      "id": "d0a9a8af402d16ee"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "de5dd48a3fc6580c"
      },
      "outputs": [],
      "source": [
        "class GATLayer(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(2 * hidden_size, hidden_size)\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor | None,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        start_nodes, end_nodes = graph.edges(\n",
        "            order='srcdst')  # note that our graph is bi-directed and contains self-loops\n",
        "\n",
        "        messages = self.linear_1(node_embeddings)\n",
        "        messages_i = messages[start_nodes]\n",
        "        messages_j = messages[end_nodes]\n",
        "\n",
        "        concat_messages = torch.cat([messages_i, messages_j], dim=-1)\n",
        "        scores = self.leaky_relu(self.linear_2(concat_messages))\n",
        "\n",
        "        exp_scores = torch.exp(scores)\n",
        "        scores_dense, mask = to_dense_batch(exp_scores, start_nodes.long(), fill_value=0.0)\n",
        "        alphas = scores_dense/scores_dense.sum(dim=1, keepdim=True)\n",
        "\n",
        "        message_j_dense, _ = to_dense_batch(messages_j, start_nodes.long(), fill_value=0.0)\n",
        "        output = (alphas * message_j_dense).sum(dim=1)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "test_gnn_layer(GATLayer, expected_gat_output)"
      ],
      "id": "de5dd48a3fc6580c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "7b21c9263771dfe"
      },
      "source": [
        "## Dot-product attention\n",
        "Having the GAT implemented, we can move to the attention used in the Transformer model. It's called \"multi-head dot-product attention\", but for the moment let's focus on the \"dot-product\" part of the name."
      ],
      "id": "7b21c9263771dfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bfb71775af4b9db9"
      },
      "source": [
        "### Task 2. Dot-product attention (2 points).\n",
        "Your task is to:\n",
        "1\\) implement the dot-product attention given by the following formula:\n",
        "$$\n",
        "v_i = W_v x_i, \\quad k_i = W_k x_i, \\quad q_i = W_q x_i, \\quad W_v, W_k, W_q \\in \\mathbb{R}^{D \\times D}, \\quad x_i \\in \\mathbb{R}^{D}\n",
        "$$\n",
        "$$\n",
        "score_{ij} = \\frac{q_i^T k_j}{\\sqrt{D}}\n",
        "$$\n",
        "$$\n",
        "a_{ij} = \\frac{exp(score_{ij})}{\\sum_{k=1}^n exp(score_{ik})}\n",
        "$$\n",
        "$$\n",
        "x'_i = \\sum_{j=1}^n a_{ij} v_j\n",
        "$$\n",
        "2\\) Briefly explain what's the advantage of dot-product attention over the additive one.\n",
        "Your explanation: The main reason is that dot-product attention is more computationally efficient than additive attention. The reason is that the dot product is a simpler operation for the computer comparing to additive attention weighted sum. The dot-product is also higly parallelizable which helps with parallel processing using GPU's."
      ],
      "id": "bfb71775af4b9db9"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f526e48a689c5e0b"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DotProductAttention(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, output_size: int | None = None):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size or hidden_size\n",
        "        self.linear_v = nn.Linear(hidden_size, self.output_size)\n",
        "        self.linear_k = nn.Linear(hidden_size, self.output_size)\n",
        "        self.linear_q = nn.Linear(hidden_size, self.output_size)\n",
        "        self.sqrt_d = np.sqrt(self.output_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "            mask: a mask indicating which nodes are real, i.e. [batch_size, max_num_nodes]\n",
        "        Returns:\n",
        "            node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        values = self.linear_v(node_embeddings)\n",
        "        keys = self.linear_k(node_embeddings)\n",
        "        queries = self.linear_q(node_embeddings)\n",
        "\n",
        "        scores = torch.matmul(queries, keys.transpose(1, 2)) / self.sqrt_d\n",
        "        scores = scores.masked_fill(mask.unsqueeze(-1) == 0, float('-inf'))\n",
        "        scores = scores.masked_fill(mask.unsqueeze(-1).transpose(1,2) == 0, float('-inf'))\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        attention_weights = torch.nan_to_num(attention_weights)\n",
        "\n",
        "        attention_values = torch.matmul(attention_weights, values)\n",
        "\n",
        "        return attention_values\n",
        "\n",
        "torch.set_printoptions(precision=6)\n",
        "test_gnn_layer(DotProductAttention, expected_dot_attention_output, requires_dense=True)"
      ],
      "id": "f526e48a689c5e0b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "d343acfdedd08d0e"
      },
      "source": [
        "## Multi-head dot-product attention\n",
        "Great! We can now implement the actual attention used in the Transformer!\n",
        "### Task 3. Multi-head dot-product attention (2 points).\n",
        "Your task is to:\n",
        "1\\) Implement multi-head dot-product attention (in a naive form). Let's parametrize the attention from the previous task with $W_v, W_k, W_q$ matrices so that we can rewrite it:\n",
        "$$\n",
        "x'_i = attention(W_v, W_k, W_q)\n",
        "$$\n",
        "The multi-head attention is a simple concatenation of the outputs of different attentions and is give by the following formula:\n",
        "$$\n",
        "x'_i = concat(attention_1(W_v^{(1)}, W_k^{(1)}, W_q^{(1)}), \\dots, attention_H(W_v^{(H)}, W_k^{(H)}, W_q^{(H)}))W\n",
        "$$\n",
        "where matrices $W_v^{(h)}, W_k^{(h)}, W_q^{(h)} \\in \\mathbb{R}^{(D / H) \\times D}$ are distinct for each head $h \\in \\{1, \\dots, H\\}$ and have reduced output sizes. The matrix $W \\in \\mathbb{R}^{D \\times D}$.\n",
        "2\\) Briefly explain what is the advantage of the multi-head dot-product attention over the (single-head) dot-product one.\n",
        "Your explanation: The main reason is that multi-head attention allows the model to attend to different parts of the input sequence in parallel, while using different learned projection weights, the model gains expressivity and is able to learn more complex representations.\n"
      ],
      "id": "d343acfdedd08d0e"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e4630245780b0520"
      },
      "outputs": [],
      "source": [
        "class SuboptimalMultiHeadAttention(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, n_heads: int = 3):\n",
        "        super().__init__()\n",
        "        assert hidden_size % n_heads == 0\n",
        "        self.output_linear = nn.Linear(hidden_size, hidden_size)  # the last linear layer (W)\n",
        "        self.attentions = nn.ModuleList()\n",
        "        for _ in range(n_heads):\n",
        "            attention = DotProductAttention(hidden_size, output_size=int(hidden_size/n_heads))\n",
        "            self.attentions.append(attention)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        outputs = []\n",
        "\n",
        "        for attention_head in self.attentions:\n",
        "            head_output = attention_head(node_embeddings, mask, graph)\n",
        "            outputs.append(head_output)\n",
        "\n",
        "        multi_head_output = torch.cat(outputs, dim=-1)\n",
        "        output = self.output_linear(multi_head_output)\n",
        "        output = output.masked_fill(mask.unsqueeze(-1) == 0, 0)\n",
        "\n",
        "        return output\n",
        "\n",
        "test_gnn_layer(SuboptimalMultiHeadAttention, sub_optimal_multihead_attention_output, requires_dense=True)"
      ],
      "id": "e4630245780b0520"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9729ec99e9d044ea"
      },
      "source": [
        "### Task 4. Multi-head dot-product attention (2 points).\n",
        "The attention from the previous task works, but requires to loop over `n_attention` heads. We can avoid that! Your task is to implement multi-head dot-product attention defined in the previous task in a batch-manner (without using loops)."
      ],
      "id": "9729ec99e9d044ea"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ba21c935ca28de42"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, n_heads: int = 3):\n",
        "        super().__init__()\n",
        "        assert hidden_size % n_heads == 0\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_heads = n_heads\n",
        "        self.linear_v = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_k = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_q = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_out = nn.Linear(hidden_size, hidden_size)\n",
        "        self.sqrt_d = np.sqrt(hidden_size // n_heads)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "            mask: a mask indicating which nodes are real, i.e. [batch_size, max_num_nodes]\n",
        "        Returns:\n",
        "            node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        values = self.linear_v(node_embeddings)\n",
        "        keys = self.linear_k(node_embeddings)\n",
        "        queries = self.linear_q(node_embeddings)\n",
        "\n",
        "        values = values.reshape(values.shape[0], values.shape[1], self.n_heads,\n",
        "                                -1)  # [batch_size, max_num_nodes, n_heads, hidden_size // n_heads]\n",
        "        keys = keys.reshape(keys.shape[0], keys.shape[1], self.n_heads,\n",
        "                            -1)  # [batch_size, max_num_nodes, n_heads, hidden_size // n_heads]\n",
        "        queries = queries.reshape(queries.shape[0], queries.shape[1], self.n_heads,\n",
        "                                  -1)  # [batch_size, max_num_nodes, n_heads, hidden_size // n_heads]\n",
        "        values = values.transpose(-2, -3)  # [batch_size, n_heads, max_num_nodes, hidden_size // n_heads]\n",
        "        keys = keys.transpose(-2, -3)  # [batch_size, n_heads, max_num_nodes, hidden_size // n_heads]\n",
        "        queries = queries.transpose(-2, -3)  # [batch_size, n_heads, max_num_nodes, hidden_size // n_heads]\n",
        "\n",
        "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / self.sqrt_d\n",
        "        scores = scores.masked_fill(mask.unsqueeze(1).unsqueeze(-1) == 0, float('-inf'))\n",
        "        scores = scores.masked_fill(mask.unsqueeze(1).unsqueeze(-1).transpose(2,3) == 0, float('-inf'))\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        attention_values = torch.matmul(attention_weights, values)\n",
        "        attention_values = attention_values.transpose(-2, -3).reshape(node_embeddings.shape)\n",
        "        output = self.linear_out(attention_values)\n",
        "        output = output.masked_fill(mask.unsqueeze(-1) == 0, 0)\n",
        "\n",
        "        return output\n",
        "\n",
        "test_gnn_layer(MultiHeadAttention, expected_multihead_attention_output, requires_dense=True)"
      ],
      "id": "ba21c935ca28de42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1831a36671fc22ad"
      },
      "source": [
        "# Transformer\n",
        "We have implemented the attention mechanism. Transformer also consist of other parts but they're rather boring and here's the implementation:\n"
      ],
      "id": "1831a36671fc22ad"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "867fc56c03dce698"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, n_heads: int = 4):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attention = MultiHeadAttention(hidden_size=hidden_size, n_heads=n_heads)\n",
        "        self.norm_1 = nn.LayerNorm(hidden_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "        self.norm_2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        node_embeddings = self.attention(node_embeddings, mask, graph) + node_embeddings\n",
        "        node_embeddings = self.norm_1(node_embeddings)\n",
        "        node_embeddings = self.feed_forward(node_embeddings) + node_embeddings\n",
        "        node_embeddings = self.norm_2(node_embeddings)\n",
        "        node_embeddings = torch.masked_fill(node_embeddings, ~mask.unsqueeze(-1), 0.0)\n",
        "        return node_embeddings"
      ],
      "id": "867fc56c03dce698"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "23e4eb54dd80f7f1"
      },
      "source": [
        "## Expressiveness of a Transformer as GNN\n",
        "Let's play for a while with the expressiveness of a TransformerLayer in a GNN. For that purpose, let us simplify the graph featurizer used to transform a SMILES to a graph as much as possible, so that the featurized graph contains only the information about the atom tyoe."
      ],
      "id": "23e4eb54dd80f7f1"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "38de5b1c72850c4f"
      },
      "outputs": [],
      "source": [
        "from dgllife.utils import BaseAtomFeaturizer, ConcatFeaturizer, atom_type_one_hot\n",
        "\n",
        "atom_type_featurizer = BaseAtomFeaturizer(\n",
        "    featurizer_funcs={\n",
        "        \"h\": ConcatFeaturizer([atom_type_one_hot]),\n",
        "    }\n",
        ")\n",
        "smiles_to_graph_simple = SMILESToBigraph(\n",
        "    node_featurizer=atom_type_featurizer,\n",
        "    add_self_loop=True,\n",
        ")"
      ],
      "id": "38de5b1c72850c4f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "db9a6076f9a98a"
      },
      "source": [
        "Let us also define some GNN constructor wrappers for convenience:"
      ],
      "id": "db9a6076f9a98a"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e26eba5e28ca0243"
      },
      "outputs": [],
      "source": [
        "def transformer_gnn(node_features_size: int, n_layers: int) -> GNN:\n",
        "    return GNN(\n",
        "        node_features_size=node_features_size,\n",
        "        hidden_size=64,\n",
        "        output_size=1,\n",
        "        gnn_layer_cls=TransformerLayer,\n",
        "        gnn_layer_kwargs={},\n",
        "        gnn_n_layers=n_layers,\n",
        "        gnn_layer_requires_dense=True,\n",
        "        readout_cls=SumReadout,\n",
        "    )\n",
        "\n",
        "\n",
        "def gat_gnn(node_features_size: int, n_layers: int) -> GNN:\n",
        "    return GNN(\n",
        "        node_features_size=node_features_size,\n",
        "        hidden_size=64,\n",
        "        output_size=1,\n",
        "        gnn_layer_cls=GATLayer,\n",
        "        gnn_layer_kwargs={},\n",
        "        gnn_n_layers=n_layers,\n",
        "        gnn_layer_requires_dense=False,\n",
        "        readout_cls=SumReadout,\n",
        "    )\n"
      ],
      "id": "e26eba5e28ca0243"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eda57840c03d7afd"
      },
      "source": [
        "And define two molecules that are pretty dissimilar:"
      ],
      "id": "eda57840c03d7afd"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "6fd3d0946ae2c05",
        "outputId": "f9feeed6-1f6c-4e6f-e4ec-0e2a5e42bc89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7c80ed8df990>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from rdkit.Chem import MolFromSmiles\n",
        "\n",
        "smiles_a = \"NSCCN\"\n",
        "MolFromSmiles(smiles_a)"
      ],
      "id": "6fd3d0946ae2c05"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "df34e6eb7b9b042c",
        "outputId": "75277367-5068-4285-c11f-33175f2b5c1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7c80ed8dfb50>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "smiles_b = \"NS(CC)N\"\n",
        "MolFromSmiles(smiles_b)"
      ],
      "id": "df34e6eb7b9b042c"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cc86171486e10508"
      },
      "outputs": [],
      "source": [
        "graph_a = smiles_to_graph_simple(smiles_a)\n",
        "graph_b = smiles_to_graph_simple(smiles_b)\n",
        "batch = dgl.batch([graph_a, graph_b])"
      ],
      "id": "cc86171486e10508"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "c00d11652b85d1fb"
      },
      "source": [
        "### Task 5. Expressiveness of a Transformer as a GNN (2 points).\n",
        "Using the code provided below, run few experiments and answer the following questions:\n",
        "1. Explain why the Transformer-based GNN can (or cannot) distinguish between the two molecules.\n",
        "2. Why can (or cannot) we make the Transformer-based GNN to distinguish between the molecules by manipulating the number of layers?\n",
        "3. Explain why the GAT-based GNN can (or cannot) distinguish between the two molecules.\n",
        "4. Why can (or cannot) we make the GAT-based GNN to distinguish between the molecules by manipulating the number of layers?"
      ],
      "id": "c00d11652b85d1fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJLfKpIiKqmY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.   The Transformer-based Graph Neural Network (GNN) may have problems to distinguish between two molecules. The reason is that it doesn't have information about the positions of nodes within the graph and it's structural relationships. Transformers without some sort of positional encodings treat all input positions equally, which results in lack of spatial information needed to distinguish between molecules.\n",
        "2.   Increasing the number of layers in a Transformer-based GNN without some sort of structural encodings doesn't help with the issue of distinguishing between molecules. The problem is in the architecture of the Transformer as mentioned in the previous answear.\n",
        "3.   The Graph Attention Network-based GNN without structural encodings is still able to distinguish between molecules. GAT's attention mechanism is able to focus on different neighbors and can capture local graph structures. However it is not as effective as it might be when we add structural encodings.\n",
        "4.   As it turns out more layers doesn't improve the ability to distinguish different molecules in this example. With an increased number of layers, the GAT-based GNN may start to prioritize global information over local information, the other reason coulb be that more complex models can have problems to generalize, which can lead to overfitting.\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "YJLfKpIiKqmY"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fae8178804eb3f",
        "outputId": "dd5df8b0-100b-440f-b259-dc9322cafe1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.789444],\n",
            "        [-0.789444]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[1.804276],\n",
            "        [1.804276]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.392649],\n",
            "        [0.392649]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-1.619401],\n",
            "        [-1.619401]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.791126],\n",
            "        [0.791126]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.120115],\n",
            "        [-0.120114]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.832805],\n",
            "        [-0.832804]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=2)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=10)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=3)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=5)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=200)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=70)\n",
        "print(transformer(batch))\n",
        "transformer = transformer_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=80)\n",
        "print(transformer(batch))\n"
      ],
      "id": "5fae8178804eb3f"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a13dd9ec9efb90b4",
        "outputId": "9cbb1259-9ed9-47ce-a2af-84efb79e0637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.365955],\n",
            "        [0.366614]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.112383],\n",
            "        [0.113800]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.088350],\n",
            "        [-0.088703]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.198945],\n",
            "        [-0.198945]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.076528],\n",
            "        [-0.076528]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.167808],\n",
            "        [0.167808]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.152705],\n",
            "        [-0.152705]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.196797],\n",
            "        [-0.196797]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.040956],\n",
            "        [0.040956]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.137768],\n",
            "        [0.137768]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=3)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=2)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=4)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=40)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=60)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=80)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=200)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=140)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=20)\n",
        "print(gat(batch))\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=20)\n",
        "print(gat(batch))"
      ],
      "id": "a13dd9ec9efb90b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5c82f3260a0c2850"
      },
      "source": [
        "# Positional Encodings\n",
        "As you finished the previous task, you know that our Transformer-based GNN cannot distinguish between the two molecules, and you know the exact reason. To overcome that reason, we can use structural encodings which are the analog of positional encodings used in the original textual Transformer. The purpose of the structural encoding is to encode the structure of a graph into the initial node features. For example, we can use the random walk positional encoding from dgllife package: [RandomWalkPE](https://docs.dgl.ai/en/1.1.x/generated/dgl.transforms.RandomWalkPE.html):\n"
      ],
      "id": "5c82f3260a0c2850"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ddceef663c774550"
      },
      "outputs": [],
      "source": [
        "from dgllife.utils.mol_to_graph import construct_bigraph_from_mol\n",
        "from dgl import random_walk_pe\n",
        "from rdkit import Chem\n",
        "\n",
        "\n",
        "class PositionalEncodingFeaturizerBase:\n",
        "    @abstractmethod\n",
        "    def feat_size(self) -> int:\n",
        "        pass\n",
        "\n",
        "\n",
        "class JointFeaturizer:\n",
        "    def __init__(self, atom_featurizer: BaseAtomFeaturizer, pe_featurizer: PositionalEncodingFeaturizerBase):\n",
        "        self.atom_featurizer = atom_featurizer\n",
        "        self.pe_featurizer = pe_featurizer\n",
        "\n",
        "    def feat_size(self) -> int:\n",
        "        return self.atom_featurizer.feat_size() + self.pe_featurizer.feat_size()\n",
        "\n",
        "    def __call__(self, mol: Chem.Mol):\n",
        "        atom_features = self.atom_featurizer(mol)['h']\n",
        "        pe_features = self.pe_featurizer(mol)\n",
        "        return {'h': torch.cat([atom_features, pe_features], dim=-1)}\n",
        "\n",
        "\n",
        "class RandomWalkPEFeaturizer(PositionalEncodingFeaturizerBase):\n",
        "    def __init__(self, n_steps: int = 16):\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def feat_size(self) -> int:\n",
        "        return self.n_steps\n",
        "\n",
        "    def __call__(self, mol: Chem.Mol):\n",
        "        graph = construct_bigraph_from_mol(mol)\n",
        "        return random_walk_pe(\n",
        "            graph, k=self.n_steps\n",
        "        )\n"
      ],
      "id": "ddceef663c774550"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "524c9eca4085690b"
      },
      "source": [
        "## Task 6. Random walk. (1 points).\n",
        "Given the following code:\n",
        "```\n",
        "smiles = 'C1CCC2CCCCC2C1'\n",
        "mol = MolFromSmiles(smiles)\n",
        "output = RandomWalkPEFeaturizer(n_steps=16)(mol)\n",
        "```\n",
        "Briefly explain the meaning of the `output[i, k]` value. Is it a probability of some event? What is the event?"
      ],
      "id": "524c9eca4085690b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dERoMLQMmkS"
      },
      "source": [
        "From how i understand it, the output[i, k] is the probability of the event that the random walk is in the certain atom after k steps when starting from i'th atom.\n"
      ],
      "id": "8dERoMLQMmkS"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "65c90e737702c5c9"
      },
      "outputs": [],
      "source": [
        "node_pe_featurizer = JointFeaturizer(\n",
        "    atom_featurizer=atom_type_featurizer,\n",
        "    pe_featurizer=RandomWalkPEFeaturizer(n_steps=16),\n",
        ")\n",
        "smiles_to_graph_pe = SMILESToBigraph(\n",
        "    node_featurizer=node_pe_featurizer,\n",
        "    add_self_loop=True,\n",
        ")"
      ],
      "id": "65c90e737702c5c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "e1159b480bf8318a"
      },
      "source": [
        "We can now observe the effect of the positional encodings on the Transformer-based GNN:"
      ],
      "id": "e1159b480bf8318a"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc3d7cc36db923c2",
        "outputId": "9e51ffd8-a821-4e91-b3f3-ec9ba559ec24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:53: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return th.as_tensor(data, dtype=dtype)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.070284],\n",
              "        [-0.067226]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "graph_a = smiles_to_graph_pe(smiles_a)\n",
        "graph_b = smiles_to_graph_pe(smiles_b)\n",
        "batch = dgl.batch([graph_a, graph_b])\n",
        "transformer = transformer_gnn(node_features_size=node_pe_featurizer.feat_size(), n_layers=3)\n",
        "transformer(batch)"
      ],
      "id": "fc3d7cc36db923c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "325168c4a48f62e8"
      },
      "source": [
        "## Random Walk and expressiveness of MPNNs\n",
        "Using random walk as a positional encoding can also help MPNN to be more expressive (distinguish more non-isomorphic graphs)."
      ],
      "id": "325168c4a48f62e8"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "b495d6fbe406181d",
        "outputId": "7ada4a16-7c94-4d4b-f705-65e05c2e1615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7c80ed925b60>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "smiles_a = 'C1CCC2CCCCC2C1'\n",
        "MolFromSmiles(smiles_a)"
      ],
      "id": "b495d6fbe406181d"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "7a40bd3dea5767d",
        "outputId": "ce18810e-c30e-41c1-91a7-e9aed71a51a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7c80ed925e70>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "smiles_b = 'C1CCC(C1)C2CCCC2'\n",
        "MolFromSmiles(smiles_b)"
      ],
      "id": "7a40bd3dea5767d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2308b8a27ebcd713"
      },
      "source": [
        "### Task 7. Expressiveness of a MPNN (2 points).\n",
        "Using the code provided below, run few experiments and answer the following questions:\n",
        "1. Explain why the GAT-based GNN can (or cannot) distinguish between the two molecules.\n",
        "2. Explain why the Transformer-based GNN with random walk positional encodings can (or cannot) distinguish between the two molecules.\n",
        "3. Explain why the GAT-based GNN with random walk positional encodings can (or cannot) distinguish between the two molecules."
      ],
      "id": "2308b8a27ebcd713"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olA_Z_e6Itys"
      },
      "source": [
        "1.   Here we can see that the GAT-based GNN by itself doesn't have enough powet to distinguish between two different molecules. As mentioned in question 5, some sort of structural encoding could help with that.\n",
        "2.   Adding random walk positional encodings to a Transformer-based GNN can improve its ability to distinguish between molecules. Positional encodings takes in to account the structural information considering the local graph context, which helps to learn spatial relationships between nodes. Random walk positional encodings can provide the model with a sense of the order in which nodes are visited during random walks. This information can improve the model's ability to distinguish different molecules.\n",
        "3.   Adding random walk positional encodings into a GAT-based GNN can further improve its ability to distinguish between molecules. Adding structural encodings to attention mechanism in GAT allows to find important local structures in graph and improves its discriminative abilities. Random walk positional encodings can provide the model with a sense of the order in which nodes are visited during random walks.\n"
      ],
      "id": "olA_Z_e6Itys"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f9bad16b6026e8",
        "outputId": "5185f0fc-a04a-46d3-dd80-46b07ac93077"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.141115],\n",
              "        [-0.141115]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "graph_a = smiles_to_graph_simple(smiles_a)\n",
        "graph_b = smiles_to_graph_simple(smiles_b)\n",
        "batch = dgl.batch([graph_a, graph_b])\n",
        "gat = gat_gnn(node_features_size=atom_type_featurizer.feat_size(), n_layers=5)\n",
        "gat(batch)"
      ],
      "id": "e0f9bad16b6026e8"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0e56cf32385de74",
        "outputId": "7fe6bd48-2997-4d71-b45c-4d6ffc5d839a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.450411],\n",
              "        [3.743921]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "graph_a = smiles_to_graph_pe(smiles_a)\n",
        "graph_b = smiles_to_graph_pe(smiles_b)\n",
        "batch = dgl.batch([graph_a, graph_b])\n",
        "transformer = transformer_gnn(node_features_size=node_pe_featurizer.feat_size(), n_layers=3)\n",
        "transformer(batch)"
      ],
      "id": "c0e56cf32385de74"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7afa6857d6a27b8f",
        "outputId": "95f8df40-5ebb-4475-841a-54960070caa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.184316],\n",
              "        [0.186424]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "graph_a = smiles_to_graph_pe(smiles_a)\n",
        "graph_b = smiles_to_graph_pe(smiles_b)\n",
        "batch = dgl.batch([graph_a, graph_b])\n",
        "gat = gat_gnn(node_features_size=node_pe_featurizer.feat_size(), n_layers=3)\n",
        "gat(batch)"
      ],
      "id": "7afa6857d6a27b8f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2f73a37520e03b08"
      },
      "source": [
        "# Experiments\n",
        "Ok, now we can quickly play with the Transformer-based and GAT-based GNNs and see how it performs on the molecular property prediction task."
      ],
      "id": "2f73a37520e03b08"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cc8e67041a8ce0ef"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "from torchmetrics import MeanSquaredError as MSE\n",
        "from torchmetrics import PearsonCorrCoef as PCC\n",
        "\n",
        "metrics = {\n",
        "    \"mae\": MAE(),\n",
        "    \"mse\": MSE(),\n",
        "    \"pcc\": PCC(),\n",
        "}\n",
        "\n",
        "\n",
        "def get_time_stamp() -> str:\n",
        "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "id": "cc8e67041a8ce0ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "150ba1690f21ae1"
      },
      "source": [
        "## Task 8. Train GAT (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GAT` as a layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture so it uses regularization tricks. You can also change the featurization functions. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc]"
      ],
      "id": "150ba1690f21ae1"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658,
          "referenced_widgets": [
            "c91ea70239884c37b96cf54d0f21ce7f",
            "e86c192c7a994652a4bc30b9ea1d6812",
            "df7db6b2d73e4be2941f8a1235629962",
            "d28a615fe6544e16946c28269d3e9f62",
            "5d2e1487edb5461fa1a0be2c5540f2d7",
            "6b6c93d6bb8646649e5ac2904327512d",
            "6fc45fdc10c54c2f8e69f25828f41d2d",
            "7fe95aaeb7b346c7a81f40714e52db6a",
            "0a765f5189824ec1ad28bf7152ff22dd",
            "15632c599b8845dda438cb019842b224",
            "afdcff0516034c4eb1a61db43c2fd749",
            "dafa5ef9aca04f279dbed159bd017c86",
            "b6342dd5cfee4b7688a7ec82880e6456",
            "24771219719a4c1cbd66203a2e390599",
            "758c14d5ec654916b4b17e9e7260bc3f",
            "49bb3cd3b48346e5afefa5513755f726",
            "fe1b7745353d4298b7b63aea1bf770df",
            "0e709f7c376b4bb9931e624901e2bc7d",
            "90d98c12d77e45dca26cc94b6d04a433",
            "4153d31c4fcb407c8c1644a7c5b8e270",
            "8b9b0fc716dc4677a240b5d4769c72ff",
            "e0dc84c79ad445cb85da117bcac36bae",
            "d41acce9d9ee4cc9b91c90fded5ee7c9",
            "c4f174501ae449759071e10ce7f9e5e7",
            "df1827db676b46d4a0cb380a5005d604",
            "e829f280f9f145fb80fa5729b475cd86",
            "20d4e6de87fa4c80bf6fb2eb7ae9181d"
          ]
        },
        "id": "88d133d593488f17",
        "outputId": "6151b717-489b-4361-caa5-3d7110bc9dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dgl graphs from scratch...\n",
            "Start initializing RDKit molecule instances...\n",
            "Start computing Bemis-Murcko scaffolds.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114014266670184, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c91ea70239884c37b96cf54d0f21ce7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/mpnn/wandb/run-20240123_163140-wa2xu8fc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc' target=\"_blank\">gat_2024-01-23_16-31-40</a></strong> to <a href='https://wandb.ai/teddy8/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/teddy8/mldd23' target=\"_blank\">https://wandb.ai/teddy8/mldd23</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc' target=\"_blank\">https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a765f5189824ec1ad28bf7152ff22dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4153d31c4fcb407c8c1644a7c5b8e270"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>▇▄▅▃▄▄█▃▄▃▇▄▄▆▄▃▅▂▂▂▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▁▂</td></tr><tr><td>train/mae</td><td>▆▄▅▄▅▄█▄▄▄▅▄▄▅▄▄▄▃▃▃▃▃▃▃▂▁▃▂▃▃▃▂▂▃▃▂▂▂▂▃</td></tr><tr><td>train/mse</td><td>▇▄▅▃▄▄█▃▄▃▇▄▄▆▄▃▅▂▂▂▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▁▂</td></tr><tr><td>train/pcc</td><td>▃▅▁▄▄▂ ▅▃▄▄▄▆▅▄▆▆▆▇▇▇▇▆▇▇ ██▆▇█▇▇▇▇█████</td></tr><tr><td>valid/loss</td><td>█▆▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/mae</td><td>█▆▅▅▅▅▅▅▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>valid/mse</td><td>█▆▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/pcc</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▄▅▆▇▇▇▇██▇██████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>6.55024</td></tr><tr><td>test/mae</td><td>2.1945</td></tr><tr><td>test/mse</td><td>7.85157</td></tr><tr><td>test/pcc</td><td>0.76065</td></tr><tr><td>train/loss</td><td>0.54383</td></tr><tr><td>train/mae</td><td>0.73745</td></tr><tr><td>train/mse</td><td>0.54383</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>9.28593</td></tr><tr><td>valid/mae</td><td>1.90237</td></tr><tr><td>valid/mse</td><td>9.28593</td></tr><tr><td>valid/pcc</td><td>0.91102</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gat_2024-01-23_16-31-40</strong> at: <a href='https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc' target=\"_blank\">https://wandb.ai/teddy8/mldd23/runs/wa2xu8fc</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>runs/mpnn/wandb/run-20240123_163140-wa2xu8fc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'loss': 9.285930514335632, 'mae': 1.9023702144622803, 'mse': 9.285930633544922, 'pcc': 0.9110189080238342}\n",
            "Test metrics: {'loss': 6.550235378742218, 'mae': 2.1944973468780518, 'mse': 7.851574420928955, 'pcc': 0.7606539130210876}\n"
          ]
        }
      ],
      "source": [
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        add_self_loop=True,\n",
        "    )\n",
        ")\n",
        "splitter = ScaffoldSplitter()\n",
        "train, valid, test = splitter.train_val_test_split(dataset)  # it's deterministic\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=node_featurizer.feat_size(),\n",
        "    hidden_size=64,\n",
        "    output_size=1,\n",
        "    gnn_layer_cls=GATLayer,\n",
        "    gnn_layer_kwargs={},\n",
        "    gnn_n_layers=4,\n",
        "    gnn_layer_requires_dense=False,\n",
        "    readout_cls=SumReadout,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    run_dir=\"experiments\",\n",
        "    train_dataset=train,\n",
        "    valid_dataset=valid,\n",
        "    train_metrics=metrics,\n",
        "    valid_metrics=metrics,\n",
        "    train_batch_size=32,\n",
        "    model=model,\n",
        "    logger=WandbLogger(\n",
        "        logdir=\"runs/mpnn\",\n",
        "        project_name=\"mldd23\",\n",
        "        experiment_name=f\"gat_{get_time_stamp()}\",\n",
        "    ),\n",
        "    optimizer_kwargs={\"lr\": 1e-4},\n",
        "    n_epochs=100,\n",
        "    device=\"cpu\",\n",
        "    valid_every_n_epochs=1,\n",
        ")\n",
        "\n",
        "valid_metrics = trainer.train()\n",
        "test_metrics = trainer.test(test)\n",
        "trainer.close()\n",
        "print(f\"Validation metrics: {valid_metrics}\")\n",
        "print(f\"Test metrics: {test_metrics}\")"
      ],
      "id": "88d133d593488f17"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5UVTtOi4QhZI"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(GNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, n_heads: int = 4):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attention = SuboptimalMultiHeadAttention(hidden_size=hidden_size, n_heads=n_heads)\n",
        "        self.norm_1 = nn.LayerNorm(hidden_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "        self.norm_2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                mask: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        node_embeddings = self.attention(node_embeddings, mask, graph) + node_embeddings\n",
        "        node_embeddings = self.norm_1(node_embeddings)\n",
        "        node_embeddings = self.feed_forward(node_embeddings) + node_embeddings\n",
        "        node_embeddings = self.norm_2(node_embeddings)\n",
        "        node_embeddings = torch.masked_fill(node_embeddings, ~mask.unsqueeze(-1), 0.0)\n",
        "        return node_embeddings"
      ],
      "id": "5UVTtOi4QhZI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8daf4b31a12b2d44"
      },
      "source": [
        "## Task 9. Train Transformer (2 points).\n",
        "1. Tune hyperparameters of a GNN with `Transformer` as a layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture so it uses regularization tricks. You can also change the featurization functions. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn]"
      ],
      "id": "8daf4b31a12b2d44"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "181a792dd28c42198633adc1816f6608",
            "014b57c9ab6b48b2b5ecc43ada8f709f",
            "261ceab6dc674ec6b38202c77bb1fa6c",
            "37fecb9fa58a423ca405946c6af385af",
            "143c04a8f4f14a509618e5d361d3cdf1",
            "3df592db2be24977920118907e2ee7f6",
            "471d39bbf5f744bab0056ec91e3faf16",
            "5d8351e09a9740df85f34eb6a70f75c2",
            "ef8b2678ebb14572bb08e6b9ae02c317",
            "7e576edb5ef64576909540ebecf76483",
            "7da8397f7c8c47ea8c1835ca562cf1c1",
            "754a11f70408414799f13f42ec58307a",
            "d55d56d05cef4426802dbddf8263e170",
            "216a4fb610d8486d8a06c95b3ea73910",
            "a9b3fa0317964e7186dcd55abef5ae65",
            "5b72fd0e5be3473fbebc059d224a4358",
            "e3938116754f475992a1d9e7608bddaa",
            "b5f5b594f4164b2db046d2d6e08dee4f",
            "a50035a169a847da942cdd22df4304d3"
          ]
        },
        "id": "48dee744e7245865",
        "outputId": "0633b3d6-ffd8-4131-df99-867c28675f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dgl graphs from scratch...\n",
            "Start initializing RDKit molecule instances...\n",
            "Start computing Bemis-Murcko scaffolds.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/mpnn/wandb/run-20240123_165440-o8g9b7sn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn' target=\"_blank\">transformer_2024-01-23_16-54-40</a></strong> to <a href='https://wandb.ai/teddy8/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/teddy8/mldd23' target=\"_blank\">https://wandb.ai/teddy8/mldd23</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn' target=\"_blank\">https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "181a792dd28c42198633adc1816f6608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "754a11f70408414799f13f42ec58307a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>█▅▃▄▄▂▁▃▃▁▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train/mae</td><td>█▆▄▅▅▄▂▄▄▃▃▃▃▃▃▃▃▃▃▂▂▃▃▂▃▁▂▂▃▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train/mse</td><td>█▅▃▄▄▂▁▃▃▁▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train/pcc</td><td>▁▃▆▆▅▇ ▇▇█▇▇▇▇▇▇█▇▇███▇██ █▇███████████▇</td></tr><tr><td>valid/loss</td><td>█▇▆▅▅▄▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/mae</td><td>██▇▆▆▄▆▄▄▃▃▂▃▃▂▄▂▂▃▂▂▁▂▁▁▁▁▂▁▂▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>valid/mse</td><td>█▇▆▅▅▄▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid/pcc</td><td>▁▂▃▅▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>5.609</td></tr><tr><td>test/mae</td><td>1.87381</td></tr><tr><td>test/mse</td><td>6.88326</td></tr><tr><td>test/pcc</td><td>0.7746</td></tr><tr><td>train/loss</td><td>0.97935</td></tr><tr><td>train/mae</td><td>0.98962</td></tr><tr><td>train/mse</td><td>0.97935</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>8.0457</td></tr><tr><td>valid/mae</td><td>1.92643</td></tr><tr><td>valid/mse</td><td>8.0457</td></tr><tr><td>valid/pcc</td><td>0.8893</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">transformer_2024-01-23_16-54-40</strong> at: <a href='https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn' target=\"_blank\">https://wandb.ai/teddy8/mldd23/runs/o8g9b7sn</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>runs/mpnn/wandb/run-20240123_165440-o8g9b7sn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'loss': 8.045702397823334, 'mae': 1.9264287948608398, 'mse': 8.04570198059082, 'pcc': 0.8893024325370789}\n",
            "Test metrics: {'loss': 5.608997131884098, 'mae': 1.8738071918487549, 'mse': 6.883261680603027, 'pcc': 0.7746005654335022}\n"
          ]
        }
      ],
      "source": [
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        add_self_loop=True,\n",
        "    )\n",
        ")\n",
        "splitter = ScaffoldSplitter()\n",
        "train, valid, test = splitter.train_val_test_split(dataset)  # it's deterministic\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=node_featurizer.feat_size(),\n",
        "    hidden_size=8,\n",
        "    output_size=1,\n",
        "    gnn_layer_cls=TransformerLayer,\n",
        "    gnn_layer_kwargs={},\n",
        "    gnn_n_layers=3,\n",
        "    gnn_layer_requires_dense=True,\n",
        "    readout_cls=SumReadout,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    run_dir=\"experiments\",\n",
        "    train_dataset=train,\n",
        "    valid_dataset=valid,\n",
        "    train_metrics=metrics,\n",
        "    valid_metrics=metrics,\n",
        "    train_batch_size=32,\n",
        "    model=model,\n",
        "    logger=WandbLogger(\n",
        "        logdir=\"runs/mpnn\",\n",
        "        project_name=\"mldd23\",\n",
        "        experiment_name=f\"transformer_{get_time_stamp()}\",\n",
        "    ),\n",
        "    optimizer_kwargs={\"lr\": 1e-3},\n",
        "    n_epochs=100,\n",
        "    device=\"cpu\",\n",
        "    valid_every_n_epochs=1,\n",
        ")\n",
        "\n",
        "valid_metrics = trainer.train()\n",
        "test_metrics = trainer.test(test)\n",
        "trainer.close()\n",
        "print(f\"Validation metrics: {valid_metrics}\")\n",
        "print(f\"Test metrics: {test_metrics}\")"
      ],
      "id": "48dee744e7245865"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c91ea70239884c37b96cf54d0f21ce7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e86c192c7a994652a4bc30b9ea1d6812",
              "IPY_MODEL_df7db6b2d73e4be2941f8a1235629962"
            ],
            "layout": "IPY_MODEL_d28a615fe6544e16946c28269d3e9f62"
          }
        },
        "e86c192c7a994652a4bc30b9ea1d6812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2e1487edb5461fa1a0be2c5540f2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_6b6c93d6bb8646649e5ac2904327512d",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "df7db6b2d73e4be2941f8a1235629962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc45fdc10c54c2f8e69f25828f41d2d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fe95aaeb7b346c7a81f40714e52db6a",
            "value": 1
          }
        },
        "d28a615fe6544e16946c28269d3e9f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d2e1487edb5461fa1a0be2c5540f2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6c93d6bb8646649e5ac2904327512d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fc45fdc10c54c2f8e69f25828f41d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe95aaeb7b346c7a81f40714e52db6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a765f5189824ec1ad28bf7152ff22dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15632c599b8845dda438cb019842b224",
              "IPY_MODEL_afdcff0516034c4eb1a61db43c2fd749",
              "IPY_MODEL_dafa5ef9aca04f279dbed159bd017c86"
            ],
            "layout": "IPY_MODEL_b6342dd5cfee4b7688a7ec82880e6456"
          }
        },
        "15632c599b8845dda438cb019842b224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24771219719a4c1cbd66203a2e390599",
            "placeholder": "​",
            "style": "IPY_MODEL_758c14d5ec654916b4b17e9e7260bc3f",
            "value": "100%"
          }
        },
        "afdcff0516034c4eb1a61db43c2fd749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bb3cd3b48346e5afefa5513755f726",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe1b7745353d4298b7b63aea1bf770df",
            "value": 100
          }
        },
        "dafa5ef9aca04f279dbed159bd017c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e709f7c376b4bb9931e624901e2bc7d",
            "placeholder": "​",
            "style": "IPY_MODEL_90d98c12d77e45dca26cc94b6d04a433",
            "value": " 100/100 [02:11&lt;00:00,  1.30s/it]"
          }
        },
        "b6342dd5cfee4b7688a7ec82880e6456": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24771219719a4c1cbd66203a2e390599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758c14d5ec654916b4b17e9e7260bc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bb3cd3b48346e5afefa5513755f726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1b7745353d4298b7b63aea1bf770df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e709f7c376b4bb9931e624901e2bc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d98c12d77e45dca26cc94b6d04a433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4153d31c4fcb407c8c1644a7c5b8e270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b9b0fc716dc4677a240b5d4769c72ff",
              "IPY_MODEL_e0dc84c79ad445cb85da117bcac36bae"
            ],
            "layout": "IPY_MODEL_d41acce9d9ee4cc9b91c90fded5ee7c9"
          }
        },
        "8b9b0fc716dc4677a240b5d4769c72ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4f174501ae449759071e10ce7f9e5e7",
            "placeholder": "​",
            "style": "IPY_MODEL_df1827db676b46d4a0cb380a5005d604",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "e0dc84c79ad445cb85da117bcac36bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e829f280f9f145fb80fa5729b475cd86",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20d4e6de87fa4c80bf6fb2eb7ae9181d",
            "value": 1
          }
        },
        "d41acce9d9ee4cc9b91c90fded5ee7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f174501ae449759071e10ce7f9e5e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1827db676b46d4a0cb380a5005d604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e829f280f9f145fb80fa5729b475cd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d4e6de87fa4c80bf6fb2eb7ae9181d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "181a792dd28c42198633adc1816f6608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_014b57c9ab6b48b2b5ecc43ada8f709f",
              "IPY_MODEL_261ceab6dc674ec6b38202c77bb1fa6c",
              "IPY_MODEL_37fecb9fa58a423ca405946c6af385af"
            ],
            "layout": "IPY_MODEL_143c04a8f4f14a509618e5d361d3cdf1"
          }
        },
        "014b57c9ab6b48b2b5ecc43ada8f709f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3df592db2be24977920118907e2ee7f6",
            "placeholder": "​",
            "style": "IPY_MODEL_471d39bbf5f744bab0056ec91e3faf16",
            "value": "100%"
          }
        },
        "261ceab6dc674ec6b38202c77bb1fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d8351e09a9740df85f34eb6a70f75c2",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef8b2678ebb14572bb08e6b9ae02c317",
            "value": 100
          }
        },
        "37fecb9fa58a423ca405946c6af385af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e576edb5ef64576909540ebecf76483",
            "placeholder": "​",
            "style": "IPY_MODEL_7da8397f7c8c47ea8c1835ca562cf1c1",
            "value": " 100/100 [02:21&lt;00:00,  1.52s/it]"
          }
        },
        "143c04a8f4f14a509618e5d361d3cdf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df592db2be24977920118907e2ee7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471d39bbf5f744bab0056ec91e3faf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d8351e09a9740df85f34eb6a70f75c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8b2678ebb14572bb08e6b9ae02c317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e576edb5ef64576909540ebecf76483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da8397f7c8c47ea8c1835ca562cf1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754a11f70408414799f13f42ec58307a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d55d56d05cef4426802dbddf8263e170",
              "IPY_MODEL_216a4fb610d8486d8a06c95b3ea73910"
            ],
            "layout": "IPY_MODEL_a9b3fa0317964e7186dcd55abef5ae65"
          }
        },
        "d55d56d05cef4426802dbddf8263e170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b72fd0e5be3473fbebc059d224a4358",
            "placeholder": "​",
            "style": "IPY_MODEL_e3938116754f475992a1d9e7608bddaa",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "216a4fb610d8486d8a06c95b3ea73910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f5b594f4164b2db046d2d6e08dee4f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a50035a169a847da942cdd22df4304d3",
            "value": 1
          }
        },
        "a9b3fa0317964e7186dcd55abef5ae65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b72fd0e5be3473fbebc059d224a4358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3938116754f475992a1d9e7608bddaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f5b594f4164b2db046d2d6e08dee4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50035a169a847da942cdd22df4304d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}